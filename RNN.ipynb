{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMurvXmY+TcnbZTLEb7Rujp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohan0332/Capstone/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RNN"
      ],
      "metadata": {
        "id": "2P3J2kMb2Lik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "# Define the directories containing the training and testing data\n",
        "train_dir = '/content/drive/MyDrive/Capstone dataset/Images-out_RGB/train'\n",
        "test_dir = '/content/drive/MyDrive/Capstone dataset/Images-out_RGB/test'\n",
        "\n",
        "# Define the InceptionV3 model\n",
        "inception = InceptionV3(include_top=False, pooling='avg')\n",
        "\n",
        "# Define a function to extract features from a given image file\n",
        "def extract_features(file_path):\n",
        "    img = image.load_img(file_path, target_size=(299, 299))\n",
        "    x = image.img_to_array(img)\n",
        "    x = preprocess_input(x)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    features = inception.predict(x)\n",
        "    return features\n",
        "\n",
        "# Define a function to extract features from a directory of images\n",
        "def extract_features_from_dir(dir_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg','.png')):\n",
        "                file_path = os.path.join(root, file)\n",
        "                label = os.path.basename(root)\n",
        "                feature = extract_features(file_path)\n",
        "                features.append(feature)\n",
        "                labels.append(label)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Extract features from the training and testing directories\n",
        "train_features, train_labels = extract_features_from_dir(train_dir)\n",
        "test_features, test_labels = extract_features_from_dir(test_dir)\n",
        "\n",
        "# Reshape the features for use in a RNN\n",
        "num_features = train_features.shape[-1]\n",
        "train_features_rnn = train_features.reshape(train_features.shape[0], 1, num_features)\n",
        "test_features_rnn = test_features.reshape(test_features.shape[0], 1, num_features)\n",
        "\n",
        "# Convert the labels to integers\n",
        "train_labels = np.array([int(label) for label in train_labels])\n",
        "test_labels = np.array([int(label) for label in test_labels])\n"
      ],
      "metadata": {
        "id": "iaS-lapT2OJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an RNN on the features\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(1, num_features)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_features_rnn, train_labels, epochs=15, batch_size=64)\n",
        "\n",
        "# Evaluate the RNN on the test data\n",
        "loss, accuracy = model.evaluate(test_features_rnn, test_labels)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnsFh_8a4Cms",
        "outputId": "8dc60c41-16d6-4487-bc0a-a0d8a1d207c2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "8/8 [==============================] - 3s 49ms/step - loss: 0.5935 - accuracy: 0.6857\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.5049 - accuracy: 0.7531\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4767 - accuracy: 0.7673\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4395 - accuracy: 0.7939\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4086 - accuracy: 0.8204\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.3839 - accuracy: 0.8163\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.3320 - accuracy: 0.8490\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.3103 - accuracy: 0.8653\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.2764 - accuracy: 0.8837\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.2539 - accuracy: 0.8898\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.2316 - accuracy: 0.9082\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.2008 - accuracy: 0.9306\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2290 - accuracy: 0.9061\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1848 - accuracy: 0.9306\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1488 - accuracy: 0.9592\n",
            "2/2 [==============================] - 1s 16ms/step - loss: 0.5373 - accuracy: 0.8246\n",
            "Accuracy: 0.8245614171028137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wl5rnpgW3lhK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}